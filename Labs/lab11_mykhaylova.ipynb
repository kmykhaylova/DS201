{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "train = pd.read_csv('train-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit Opportunity\n",
    "In this lab, you will be using some of the regression models we have discussed to predict the price of cars.  We have divided the data set using an 80-20 train-test split.  The test data set does not include the column of prices.  Your job is to submit your predictions for price on the test data as a csv.  The 10 best predictions, in terms of RMSE will receive 10 extra points for the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 (20 pts)\n",
    "Make a multiple linear regression model for the car price (last column) using the variables that you think are appropriate from the data in train.csv. Variable selection, dummy coding should be parts of your code and the model. Print a summary of your final model and the RMSE when predicting on all of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_ID</th>\n",
       "      <th>symboling</th>\n",
       "      <th>CarName</th>\n",
       "      <th>fueltype</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>doornumber</th>\n",
       "      <th>carbody</th>\n",
       "      <th>drivewheel</th>\n",
       "      <th>enginelocation</th>\n",
       "      <th>wheelbase</th>\n",
       "      <th>...</th>\n",
       "      <th>enginesize</th>\n",
       "      <th>fuelsystem</th>\n",
       "      <th>boreratio</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compressionratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>citympg</th>\n",
       "      <th>highwaympg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>toyota corolla</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>95.7</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>2bbl</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>4800</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>8358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>bmw x3</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>101.2</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>121</td>\n",
       "      <td>4250</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>21105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>mitsubishi outlander</td>\n",
       "      <td>gas</td>\n",
       "      <td>turbo</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>96.3</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>spdi</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.46</td>\n",
       "      <td>7.5</td>\n",
       "      <td>116</td>\n",
       "      <td>5500</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>9279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198</td>\n",
       "      <td>-1</td>\n",
       "      <td>volvo 245</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>wagon</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>104.3</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>16515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>honda accord</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>96.5</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>1bbl</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.58</td>\n",
       "      <td>9.0</td>\n",
       "      <td>86</td>\n",
       "      <td>5800</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>10295.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_ID  symboling               CarName fueltype aspiration doornumber  \\\n",
       "0     162          0        toyota corolla      gas        std       four   \n",
       "1      14          0                bmw x3      gas        std       four   \n",
       "2      88          1  mitsubishi outlander      gas      turbo       four   \n",
       "3     198         -1             volvo 245      gas        std       four   \n",
       "4      41          0          honda accord      gas        std       four   \n",
       "\n",
       "     carbody drivewheel enginelocation  wheelbase  ...  enginesize  \\\n",
       "0  hatchback        fwd          front       95.7  ...          98   \n",
       "1      sedan        rwd          front      101.2  ...         164   \n",
       "2      sedan        fwd          front       96.3  ...         110   \n",
       "3      wagon        rwd          front      104.3  ...         141   \n",
       "4      sedan        fwd          front       96.5  ...         110   \n",
       "\n",
       "   fuelsystem  boreratio  stroke compressionratio horsepower  peakrpm citympg  \\\n",
       "0        2bbl       3.19    3.03              9.0         70     4800      28   \n",
       "1        mpfi       3.31    3.19              9.0        121     4250      21   \n",
       "2        spdi       3.17    3.46              7.5        116     5500      23   \n",
       "3        mpfi       3.78    3.15              9.5        114     5400      24   \n",
       "4        1bbl       3.15    3.58              9.0         86     5800      27   \n",
       "\n",
       "   highwaympg    price  \n",
       "0          34   8358.0  \n",
       "1          28  21105.0  \n",
       "2          30   9279.0  \n",
       "3          28  16515.0  \n",
       "4          33  10295.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['car_ID', 'symboling', 'CarName', 'fueltype', 'aspiration',\n",
       "       'doornumber', 'carbody', 'drivewheel', 'enginelocation', 'wheelbase',\n",
       "       'carlength', 'carwidth', 'carheight', 'curbweight', 'enginetype',\n",
       "       'cylindernumber', 'enginesize', 'fuelsystem', 'boreratio', 'stroke',\n",
       "       'compressionratio', 'horsepower', 'peakrpm', 'citympg', 'highwaympg',\n",
       "       'price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train1[['enginesize', 'horsepower', 'peakrpm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train1[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dummies = pd.get_dummies(train1.enginesize, prefix = \"en\", drop_first = True)\n",
    "hp_dummies = pd.get_dummies(train1.horsepower, prefix = \"hp\", drop_first = True)\n",
    "pr_dummies = pd.get_dummies(train1.peakrpm, prefix = \"pr\", drop_first = True)\n",
    "x2 = pd.concat([x, en_dummies], axis = 1)\n",
    "x3 = pd.concat([x2, en_dummies], axis = 1)\n",
    "x4 = pd.concat([x3, en_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   53.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Nov 2021</td> <th>  Prob (F-statistic):</th> <td>9.62e-61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:26:36</td>     <th>  Log-Likelihood:    </th> <td> -1464.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   164</td>      <th>  AIC:               </th> <td>   3017.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   120</td>      <th>  BIC:               </th> <td>   3154.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    43</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>-3361.5681</td> <td> 4519.695</td> <td>   -0.744</td> <td> 0.458</td> <td>-1.23e+04</td> <td> 5587.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>enginesize</th> <td>  114.7595</td> <td>   20.766</td> <td>    5.526</td> <td> 0.000</td> <td>   73.644</td> <td>  155.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th> <td>   41.5343</td> <td>   16.382</td> <td>    2.535</td> <td> 0.013</td> <td>    9.100</td> <td>   73.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peakrpm</th>    <td>   -0.0944</td> <td>    0.642</td> <td>   -0.147</td> <td> 0.883</td> <td>   -1.365</td> <td>    1.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_70</th>      <td> 3844.8019</td> <td> 2430.592</td> <td>    1.582</td> <td> 0.116</td> <td> -967.602</td> <td> 8657.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_79</th>      <td>-2278.3252</td> <td> 2843.714</td> <td>   -0.801</td> <td> 0.425</td> <td>-7908.681</td> <td> 3352.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_80</th>      <td> 4785.0412</td> <td> 2980.129</td> <td>    1.606</td> <td> 0.111</td> <td>-1115.406</td> <td> 1.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_90</th>      <td>-2433.5574</td> <td> 1830.894</td> <td>   -1.329</td> <td> 0.186</td> <td>-6058.600</td> <td> 1191.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_91</th>      <td>-3438.9106</td> <td> 2073.656</td> <td>   -1.658</td> <td> 0.100</td> <td>-7544.604</td> <td>  666.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_92</th>      <td>-2455.9634</td> <td> 1782.976</td> <td>   -1.377</td> <td> 0.171</td> <td>-5986.131</td> <td> 1074.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_97</th>      <td>-2187.4650</td> <td> 1731.514</td> <td>   -1.263</td> <td> 0.209</td> <td>-5615.743</td> <td> 1240.813</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_98</th>      <td>-2754.4056</td> <td> 1671.225</td> <td>   -1.648</td> <td> 0.102</td> <td>-6063.315</td> <td>  554.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_108</th>     <td>-1830.3209</td> <td> 1591.499</td> <td>   -1.150</td> <td> 0.252</td> <td>-4981.379</td> <td> 1320.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_109</th>     <td>-1863.6450</td> <td> 1612.407</td> <td>   -1.156</td> <td> 0.250</td> <td>-5056.098</td> <td> 1328.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_110</th>     <td>-2944.9123</td> <td> 1550.170</td> <td>   -1.900</td> <td> 0.060</td> <td>-6014.141</td> <td>  124.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_119</th>     <td>-2512.9314</td> <td> 2456.197</td> <td>   -1.023</td> <td> 0.308</td> <td>-7376.031</td> <td> 2350.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_120</th>     <td>-1438.2932</td> <td> 1493.928</td> <td>   -0.963</td> <td> 0.338</td> <td>-4396.167</td> <td> 1519.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_121</th>     <td> 1205.9047</td> <td> 1998.868</td> <td>    0.603</td> <td> 0.547</td> <td>-2751.715</td> <td> 5163.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_122</th>     <td>-4335.5550</td> <td> 1332.455</td> <td>   -3.254</td> <td> 0.001</td> <td>-6973.724</td> <td>-1697.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_130</th>     <td>   91.3396</td> <td> 1599.864</td> <td>    0.057</td> <td> 0.955</td> <td>-3076.279</td> <td> 3258.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_131</th>     <td>   60.9187</td> <td> 2490.570</td> <td>    0.024</td> <td> 0.981</td> <td>-4870.237</td> <td> 4992.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_132</th>     <td>-5148.3658</td> <td> 2369.087</td> <td>   -2.173</td> <td> 0.032</td> <td>-9838.994</td> <td> -457.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_134</th>     <td> 2249.1537</td> <td> 1805.715</td> <td>    1.246</td> <td> 0.215</td> <td>-1326.036</td> <td> 5824.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_136</th>     <td> -420.9998</td> <td> 1455.694</td> <td>   -0.289</td> <td> 0.773</td> <td>-3303.174</td> <td> 2461.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_140</th>     <td> -967.6024</td> <td> 1857.462</td> <td>   -0.521</td> <td> 0.603</td> <td>-4645.248</td> <td> 2710.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_141</th>     <td>  -38.8754</td> <td> 1254.367</td> <td>   -0.031</td> <td> 0.975</td> <td>-2522.436</td> <td> 2444.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_145</th>     <td> 5241.8938</td> <td> 2275.353</td> <td>    2.304</td> <td> 0.023</td> <td>  736.854</td> <td> 9746.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_146</th>     <td>-5634.2085</td> <td> 1351.209</td> <td>   -4.170</td> <td> 0.000</td> <td>-8309.507</td> <td>-2958.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_151</th>     <td> 2630.6440</td> <td> 2254.243</td> <td>    1.167</td> <td> 0.246</td> <td>-1832.600</td> <td> 7093.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_152</th>     <td>-2116.7830</td> <td> 1210.424</td> <td>   -1.749</td> <td> 0.083</td> <td>-4513.338</td> <td>  279.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_156</th>     <td>-6548.4191</td> <td> 1218.248</td> <td>   -5.375</td> <td> 0.000</td> <td>-8960.464</td> <td>-4136.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_161</th>     <td>-5353.2150</td> <td> 2221.528</td> <td>   -2.410</td> <td> 0.017</td> <td>-9751.685</td> <td> -954.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_164</th>     <td> 2129.8655</td> <td> 1418.439</td> <td>    1.502</td> <td> 0.136</td> <td> -678.545</td> <td> 4938.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_171</th>     <td>-6307.2578</td> <td> 1341.485</td> <td>   -4.702</td> <td> 0.000</td> <td>-8963.305</td> <td>-3651.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_173</th>     <td>  -53.2570</td> <td> 2157.292</td> <td>   -0.025</td> <td> 0.980</td> <td>-4324.545</td> <td> 4218.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_181</th>     <td>-7304.9071</td> <td> 1047.368</td> <td>   -6.975</td> <td> 0.000</td> <td>-9378.624</td> <td>-5231.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_183</th>     <td> 7550.4721</td> <td> 1568.659</td> <td>    4.813</td> <td> 0.000</td> <td> 4444.637</td> <td> 1.07e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_194</th>     <td> 7835.5482</td> <td> 1646.975</td> <td>    4.758</td> <td> 0.000</td> <td> 4574.653</td> <td> 1.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_203</th>     <td>   46.7768</td> <td> 2780.963</td> <td>    0.017</td> <td> 0.987</td> <td>-5459.336</td> <td> 5552.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_209</th>     <td> 8645.6488</td> <td> 1267.993</td> <td>    6.818</td> <td> 0.000</td> <td> 6135.110</td> <td> 1.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_234</th>     <td> 5138.3970</td> <td> 1661.040</td> <td>    3.093</td> <td> 0.002</td> <td> 1849.654</td> <td> 8427.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_258</th>     <td>  791.9486</td> <td> 1818.268</td> <td>    0.436</td> <td> 0.664</td> <td>-2808.096</td> <td> 4391.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_304</th>     <td> 6657.1379</td> <td> 2729.779</td> <td>    2.439</td> <td> 0.016</td> <td> 1252.366</td> <td> 1.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_308</th>     <td> 1758.0998</td> <td> 2780.567</td> <td>    0.632</td> <td> 0.528</td> <td>-3747.229</td> <td> 7263.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_326</th>     <td>-8460.0485</td> <td> 2814.486</td> <td>   -3.006</td> <td> 0.003</td> <td> -1.4e+04</td> <td>-2887.562</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.961</td> <th>  Durbin-Watson:     </th> <td>   2.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  42.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.765</td> <th>  Prob(JB):          </th> <td>6.38e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.964</td> <th>  Cond. No.          </th> <td>2.79e+15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.62e-22. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.933\n",
       "Method:                 Least Squares   F-statistic:                     53.79\n",
       "Date:                Fri, 12 Nov 2021   Prob (F-statistic):           9.62e-61\n",
       "Time:                        20:26:36   Log-Likelihood:                -1464.6\n",
       "No. Observations:                 164   AIC:                             3017.\n",
       "Df Residuals:                     120   BIC:                             3154.\n",
       "Df Model:                          43                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -3361.5681   4519.695     -0.744      0.458   -1.23e+04    5587.113\n",
       "enginesize   114.7595     20.766      5.526      0.000      73.644     155.875\n",
       "horsepower    41.5343     16.382      2.535      0.013       9.100      73.969\n",
       "peakrpm       -0.0944      0.642     -0.147      0.883      -1.365       1.176\n",
       "en_70       3844.8019   2430.592      1.582      0.116    -967.602    8657.206\n",
       "en_79      -2278.3252   2843.714     -0.801      0.425   -7908.681    3352.030\n",
       "en_80       4785.0412   2980.129      1.606      0.111   -1115.406    1.07e+04\n",
       "en_90      -2433.5574   1830.894     -1.329      0.186   -6058.600    1191.485\n",
       "en_91      -3438.9106   2073.656     -1.658      0.100   -7544.604     666.783\n",
       "en_92      -2455.9634   1782.976     -1.377      0.171   -5986.131    1074.204\n",
       "en_97      -2187.4650   1731.514     -1.263      0.209   -5615.743    1240.813\n",
       "en_98      -2754.4056   1671.225     -1.648      0.102   -6063.315     554.504\n",
       "en_108     -1830.3209   1591.499     -1.150      0.252   -4981.379    1320.737\n",
       "en_109     -1863.6450   1612.407     -1.156      0.250   -5056.098    1328.809\n",
       "en_110     -2944.9123   1550.170     -1.900      0.060   -6014.141     124.317\n",
       "en_119     -2512.9314   2456.197     -1.023      0.308   -7376.031    2350.169\n",
       "en_120     -1438.2932   1493.928     -0.963      0.338   -4396.167    1519.581\n",
       "en_121      1205.9047   1998.868      0.603      0.547   -2751.715    5163.524\n",
       "en_122     -4335.5550   1332.455     -3.254      0.001   -6973.724   -1697.386\n",
       "en_130        91.3396   1599.864      0.057      0.955   -3076.279    3258.958\n",
       "en_131        60.9187   2490.570      0.024      0.981   -4870.237    4992.074\n",
       "en_132     -5148.3658   2369.087     -2.173      0.032   -9838.994    -457.737\n",
       "en_134      2249.1537   1805.715      1.246      0.215   -1326.036    5824.343\n",
       "en_136      -420.9998   1455.694     -0.289      0.773   -3303.174    2461.174\n",
       "en_140      -967.6024   1857.462     -0.521      0.603   -4645.248    2710.043\n",
       "en_141       -38.8754   1254.367     -0.031      0.975   -2522.436    2444.685\n",
       "en_145      5241.8938   2275.353      2.304      0.023     736.854    9746.933\n",
       "en_146     -5634.2085   1351.209     -4.170      0.000   -8309.507   -2958.910\n",
       "en_151      2630.6440   2254.243      1.167      0.246   -1832.600    7093.887\n",
       "en_152     -2116.7830   1210.424     -1.749      0.083   -4513.338     279.772\n",
       "en_156     -6548.4191   1218.248     -5.375      0.000   -8960.464   -4136.374\n",
       "en_161     -5353.2150   2221.528     -2.410      0.017   -9751.685    -954.745\n",
       "en_164      2129.8655   1418.439      1.502      0.136    -678.545    4938.276\n",
       "en_171     -6307.2578   1341.485     -4.702      0.000   -8963.305   -3651.211\n",
       "en_173       -53.2570   2157.292     -0.025      0.980   -4324.545    4218.031\n",
       "en_181     -7304.9071   1047.368     -6.975      0.000   -9378.624   -5231.190\n",
       "en_183      7550.4721   1568.659      4.813      0.000    4444.637    1.07e+04\n",
       "en_194      7835.5482   1646.975      4.758      0.000    4574.653    1.11e+04\n",
       "en_203        46.7768   2780.963      0.017      0.987   -5459.336    5552.889\n",
       "en_209      8645.6488   1267.993      6.818      0.000    6135.110    1.12e+04\n",
       "en_234      5138.3970   1661.040      3.093      0.002    1849.654    8427.140\n",
       "en_258       791.9486   1818.268      0.436      0.664   -2808.096    4391.994\n",
       "en_304      6657.1379   2729.779      2.439      0.016    1252.366    1.21e+04\n",
       "en_308      1758.0998   2780.567      0.632      0.528   -3747.229    7263.429\n",
       "en_326     -8460.0485   2814.486     -3.006      0.003    -1.4e+04   -2887.562\n",
       "==============================================================================\n",
       "Omnibus:                       24.961   Durbin-Watson:                   2.149\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               42.345\n",
       "Skew:                           0.765   Prob(JB):                     6.38e-10\n",
       "Kurtosis:                       4.964   Cond. No.                     2.79e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.62e-22. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y,sm.add_constant(x2))\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   53.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Nov 2021</td> <th>  Prob (F-statistic):</th> <td>9.62e-61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:26:37</td>     <th>  Log-Likelihood:    </th> <td> -1464.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   164</td>      <th>  AIC:               </th> <td>   3017.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   120</td>      <th>  BIC:               </th> <td>   3154.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    43</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>-3336.8320</td> <td> 4486.453</td> <td>   -0.744</td> <td> 0.458</td> <td>-1.22e+04</td> <td> 5546.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>enginesize</th> <td>  114.3540</td> <td>   20.337</td> <td>    5.623</td> <td> 0.000</td> <td>   74.089</td> <td>  154.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th> <td>   41.5343</td> <td>   16.382</td> <td>    2.535</td> <td> 0.013</td> <td>    9.100</td> <td>   73.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peakrpm</th>    <td>   -0.0944</td> <td>    0.642</td> <td>   -0.147</td> <td> 0.883</td> <td>   -1.365</td> <td>    1.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_70</th>      <td> 1924.2257</td> <td> 1216.574</td> <td>    1.582</td> <td> 0.116</td> <td> -484.505</td> <td> 4332.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_79</th>      <td>-1135.5130</td> <td> 1423.708</td> <td>   -0.798</td> <td> 0.427</td> <td>-3954.355</td> <td> 1683.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_80</th>      <td> 2396.3729</td> <td> 1492.392</td> <td>    1.606</td> <td> 0.111</td> <td> -558.458</td> <td> 5351.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_90</th>      <td>-1210.8988</td> <td>  919.637</td> <td>   -1.317</td> <td> 0.190</td> <td>-3031.716</td> <td>  609.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_91</th>      <td>-1713.3727</td> <td> 1041.417</td> <td>   -1.645</td> <td> 0.103</td> <td>-3775.305</td> <td>  348.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_92</th>      <td>-1221.6963</td> <td>  896.235</td> <td>   -1.363</td> <td> 0.175</td> <td>-2996.179</td> <td>  552.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_97</th>      <td>-1086.4333</td> <td>  871.835</td> <td>   -1.246</td> <td> 0.215</td> <td>-2812.607</td> <td>  639.740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_98</th>      <td>-1369.7009</td> <td>  841.719</td> <td>   -1.627</td> <td> 0.106</td> <td>-3036.246</td> <td>  296.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_108</th>     <td> -905.6310</td> <td>  803.749</td> <td>   -1.127</td> <td> 0.262</td> <td>-2496.998</td> <td>  685.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_109</th>     <td> -922.0902</td> <td>  812.957</td> <td>   -1.134</td> <td> 0.259</td> <td>-2531.689</td> <td>  687.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_110</th>     <td>-1462.5212</td> <td>  782.382</td> <td>   -1.869</td> <td> 0.064</td> <td>-3011.583</td> <td>   86.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_119</th>     <td>-1244.7059</td> <td> 1233.687</td> <td>   -1.009</td> <td> 0.315</td> <td>-3687.319</td> <td> 1197.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_120</th>     <td> -707.1840</td> <td>  756.195</td> <td>   -0.935</td> <td> 0.352</td> <td>-2204.398</td> <td>  790.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_121</th>     <td>  615.1176</td> <td> 1007.331</td> <td>    0.611</td> <td> 0.543</td> <td>-1379.327</td> <td> 2609.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_122</th>     <td>-2155.4094</td> <td>  677.785</td> <td>   -3.180</td> <td> 0.002</td> <td>-3497.377</td> <td> -813.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_130</th>     <td>   59.6599</td> <td>  811.411</td> <td>    0.074</td> <td> 0.942</td> <td>-1546.878</td> <td> 1666.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_131</th>     <td>   44.6522</td> <td> 1252.356</td> <td>    0.036</td> <td> 0.972</td> <td>-2434.926</td> <td> 2524.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_132</th>     <td>-2559.7873</td> <td> 1189.554</td> <td>   -2.152</td> <td> 0.033</td> <td>-4915.021</td> <td> -204.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_134</th>     <td> 1139.3780</td> <td>  911.501</td> <td>    1.250</td> <td> 0.214</td> <td> -665.330</td> <td> 2944.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_136</th>     <td> -195.2933</td> <td>  734.879</td> <td>   -0.266</td> <td> 0.791</td> <td>-1650.303</td> <td> 1259.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_140</th>     <td> -467.7835</td> <td>  939.374</td> <td>   -0.498</td> <td> 0.619</td> <td>-2327.678</td> <td> 1392.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_141</th>     <td>   -3.2173</td> <td>  636.631</td> <td>   -0.005</td> <td> 0.996</td> <td>-1263.702</td> <td> 1257.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_145</th>     <td> 2637.9784</td> <td> 1144.254</td> <td>    2.305</td> <td> 0.023</td> <td>  372.434</td> <td> 4903.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_146</th>     <td>-2799.8701</td> <td>  687.510</td> <td>   -4.072</td> <td> 0.000</td> <td>-4161.092</td> <td>-1438.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_151</th>     <td> 1333.5700</td> <td> 1132.413</td> <td>    1.178</td> <td> 0.241</td> <td> -908.528</td> <td> 3575.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_152</th>     <td>-1039.9408</td> <td>  620.645</td> <td>   -1.676</td> <td> 0.096</td> <td>-2268.774</td> <td>  188.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_156</th>     <td>-3254.9478</td> <td>  622.672</td> <td>   -5.227</td> <td> 0.000</td> <td>-4487.795</td> <td>-2022.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_161</th>     <td>-2656.3320</td> <td> 1117.564</td> <td>   -2.377</td> <td> 0.019</td> <td>-4869.031</td> <td> -443.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_164</th>     <td> 1085.8165</td> <td>  722.968</td> <td>    1.502</td> <td> 0.136</td> <td> -345.611</td> <td> 2517.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_171</th>     <td>-3131.3258</td> <td>  679.826</td> <td>   -4.606</td> <td> 0.000</td> <td>-4477.333</td> <td>-1785.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_173</th>     <td>   -3.9199</td> <td> 1079.664</td> <td>   -0.004</td> <td> 0.997</td> <td>-2141.579</td> <td> 2133.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_181</th>     <td>-3628.1229</td> <td>  532.457</td> <td>   -6.814</td> <td> 0.000</td> <td>-4682.351</td> <td>-2573.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_183</th>     <td> 3799.9722</td> <td>  792.011</td> <td>    4.798</td> <td> 0.000</td> <td> 2231.845</td> <td> 5368.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_194</th>     <td> 3944.7405</td> <td>  824.410</td> <td>    4.785</td> <td> 0.000</td> <td> 2312.466</td> <td> 5577.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_203</th>     <td>   52.1796</td> <td> 1397.873</td> <td>    0.037</td> <td> 0.970</td> <td>-2715.511</td> <td> 2819.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_209</th>     <td> 4352.8322</td> <td>  629.465</td> <td>    6.915</td> <td> 0.000</td> <td> 3106.535</td> <td> 5599.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_234</th>     <td> 2604.2752</td> <td>  818.369</td> <td>    3.182</td> <td> 0.002</td> <td>  983.961</td> <td> 4224.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_258</th>     <td>  435.9171</td> <td>  889.201</td> <td>    0.490</td> <td> 0.625</td> <td>-1324.639</td> <td> 2196.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_304</th>     <td> 3377.8385</td> <td> 1334.882</td> <td>    2.530</td> <td> 0.013</td> <td>  734.865</td> <td> 6020.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_308</th>     <td>  929.1305</td> <td> 1358.755</td> <td>    0.684</td> <td> 0.495</td> <td>-1761.110</td> <td> 3619.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_326</th>     <td>-4176.2941</td> <td> 1374.178</td> <td>   -3.039</td> <td> 0.003</td> <td>-6897.071</td> <td>-1455.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_70</th>      <td> 1924.2257</td> <td> 1216.574</td> <td>    1.582</td> <td> 0.116</td> <td> -484.505</td> <td> 4332.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_79</th>      <td>-1135.5130</td> <td> 1423.708</td> <td>   -0.798</td> <td> 0.427</td> <td>-3954.355</td> <td> 1683.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_80</th>      <td> 2396.3729</td> <td> 1492.392</td> <td>    1.606</td> <td> 0.111</td> <td> -558.458</td> <td> 5351.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_90</th>      <td>-1210.8988</td> <td>  919.637</td> <td>   -1.317</td> <td> 0.190</td> <td>-3031.716</td> <td>  609.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_91</th>      <td>-1713.3727</td> <td> 1041.417</td> <td>   -1.645</td> <td> 0.103</td> <td>-3775.305</td> <td>  348.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_92</th>      <td>-1221.6963</td> <td>  896.235</td> <td>   -1.363</td> <td> 0.175</td> <td>-2996.179</td> <td>  552.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_97</th>      <td>-1086.4333</td> <td>  871.835</td> <td>   -1.246</td> <td> 0.215</td> <td>-2812.607</td> <td>  639.740</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_98</th>      <td>-1369.7009</td> <td>  841.719</td> <td>   -1.627</td> <td> 0.106</td> <td>-3036.246</td> <td>  296.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_108</th>     <td> -905.6310</td> <td>  803.749</td> <td>   -1.127</td> <td> 0.262</td> <td>-2496.998</td> <td>  685.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_109</th>     <td> -922.0902</td> <td>  812.957</td> <td>   -1.134</td> <td> 0.259</td> <td>-2531.689</td> <td>  687.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_110</th>     <td>-1462.5212</td> <td>  782.382</td> <td>   -1.869</td> <td> 0.064</td> <td>-3011.583</td> <td>   86.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_119</th>     <td>-1244.7059</td> <td> 1233.687</td> <td>   -1.009</td> <td> 0.315</td> <td>-3687.319</td> <td> 1197.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_120</th>     <td> -707.1840</td> <td>  756.195</td> <td>   -0.935</td> <td> 0.352</td> <td>-2204.398</td> <td>  790.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_121</th>     <td>  615.1176</td> <td> 1007.331</td> <td>    0.611</td> <td> 0.543</td> <td>-1379.327</td> <td> 2609.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_122</th>     <td>-2155.4094</td> <td>  677.785</td> <td>   -3.180</td> <td> 0.002</td> <td>-3497.377</td> <td> -813.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_130</th>     <td>   59.6599</td> <td>  811.411</td> <td>    0.074</td> <td> 0.942</td> <td>-1546.878</td> <td> 1666.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_131</th>     <td>   44.6522</td> <td> 1252.356</td> <td>    0.036</td> <td> 0.972</td> <td>-2434.926</td> <td> 2524.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_132</th>     <td>-2559.7873</td> <td> 1189.554</td> <td>   -2.152</td> <td> 0.033</td> <td>-4915.021</td> <td> -204.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_134</th>     <td> 1139.3780</td> <td>  911.501</td> <td>    1.250</td> <td> 0.214</td> <td> -665.330</td> <td> 2944.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_136</th>     <td> -195.2933</td> <td>  734.879</td> <td>   -0.266</td> <td> 0.791</td> <td>-1650.303</td> <td> 1259.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_140</th>     <td> -467.7835</td> <td>  939.374</td> <td>   -0.498</td> <td> 0.619</td> <td>-2327.678</td> <td> 1392.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_141</th>     <td>   -3.2173</td> <td>  636.631</td> <td>   -0.005</td> <td> 0.996</td> <td>-1263.702</td> <td> 1257.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_145</th>     <td> 2637.9784</td> <td> 1144.254</td> <td>    2.305</td> <td> 0.023</td> <td>  372.434</td> <td> 4903.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_146</th>     <td>-2799.8701</td> <td>  687.510</td> <td>   -4.072</td> <td> 0.000</td> <td>-4161.092</td> <td>-1438.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_151</th>     <td> 1333.5700</td> <td> 1132.413</td> <td>    1.178</td> <td> 0.241</td> <td> -908.528</td> <td> 3575.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_152</th>     <td>-1039.9408</td> <td>  620.645</td> <td>   -1.676</td> <td> 0.096</td> <td>-2268.774</td> <td>  188.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_156</th>     <td>-3254.9478</td> <td>  622.672</td> <td>   -5.227</td> <td> 0.000</td> <td>-4487.795</td> <td>-2022.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_161</th>     <td>-2656.3320</td> <td> 1117.564</td> <td>   -2.377</td> <td> 0.019</td> <td>-4869.031</td> <td> -443.633</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_164</th>     <td> 1085.8165</td> <td>  722.968</td> <td>    1.502</td> <td> 0.136</td> <td> -345.611</td> <td> 2517.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_171</th>     <td>-3131.3258</td> <td>  679.826</td> <td>   -4.606</td> <td> 0.000</td> <td>-4477.333</td> <td>-1785.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_173</th>     <td>   -3.9199</td> <td> 1079.664</td> <td>   -0.004</td> <td> 0.997</td> <td>-2141.579</td> <td> 2133.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_181</th>     <td>-3628.1229</td> <td>  532.457</td> <td>   -6.814</td> <td> 0.000</td> <td>-4682.351</td> <td>-2573.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_183</th>     <td> 3799.9722</td> <td>  792.011</td> <td>    4.798</td> <td> 0.000</td> <td> 2231.845</td> <td> 5368.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_194</th>     <td> 3944.7405</td> <td>  824.410</td> <td>    4.785</td> <td> 0.000</td> <td> 2312.466</td> <td> 5577.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_203</th>     <td>   52.1796</td> <td> 1397.873</td> <td>    0.037</td> <td> 0.970</td> <td>-2715.511</td> <td> 2819.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_209</th>     <td> 4352.8322</td> <td>  629.465</td> <td>    6.915</td> <td> 0.000</td> <td> 3106.535</td> <td> 5599.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_234</th>     <td> 2604.2752</td> <td>  818.369</td> <td>    3.182</td> <td> 0.002</td> <td>  983.961</td> <td> 4224.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_258</th>     <td>  435.9171</td> <td>  889.201</td> <td>    0.490</td> <td> 0.625</td> <td>-1324.639</td> <td> 2196.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_304</th>     <td> 3377.8385</td> <td> 1334.882</td> <td>    2.530</td> <td> 0.013</td> <td>  734.865</td> <td> 6020.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_308</th>     <td>  929.1305</td> <td> 1358.755</td> <td>    0.684</td> <td> 0.495</td> <td>-1761.110</td> <td> 3619.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_326</th>     <td>-4176.2941</td> <td> 1374.178</td> <td>   -3.039</td> <td> 0.003</td> <td>-6897.071</td> <td>-1455.518</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.961</td> <th>  Durbin-Watson:     </th> <td>   2.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  42.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.765</td> <th>  Prob(JB):          </th> <td>6.38e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.964</td> <th>  Cond. No.          </th> <td>7.60e+19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.54e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.933\n",
       "Method:                 Least Squares   F-statistic:                     53.79\n",
       "Date:                Fri, 12 Nov 2021   Prob (F-statistic):           9.62e-61\n",
       "Time:                        20:26:37   Log-Likelihood:                -1464.6\n",
       "No. Observations:                 164   AIC:                             3017.\n",
       "Df Residuals:                     120   BIC:                             3154.\n",
       "Df Model:                          43                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -3336.8320   4486.453     -0.744      0.458   -1.22e+04    5546.033\n",
       "enginesize   114.3540     20.337      5.623      0.000      74.089     154.619\n",
       "horsepower    41.5343     16.382      2.535      0.013       9.100      73.969\n",
       "peakrpm       -0.0944      0.642     -0.147      0.883      -1.365       1.176\n",
       "en_70       1924.2257   1216.574      1.582      0.116    -484.505    4332.957\n",
       "en_79      -1135.5130   1423.708     -0.798      0.427   -3954.355    1683.329\n",
       "en_80       2396.3729   1492.392      1.606      0.111    -558.458    5351.204\n",
       "en_90      -1210.8988    919.637     -1.317      0.190   -3031.716     609.918\n",
       "en_91      -1713.3727   1041.417     -1.645      0.103   -3775.305     348.560\n",
       "en_92      -1221.6963    896.235     -1.363      0.175   -2996.179     552.787\n",
       "en_97      -1086.4333    871.835     -1.246      0.215   -2812.607     639.740\n",
       "en_98      -1369.7009    841.719     -1.627      0.106   -3036.246     296.844\n",
       "en_108      -905.6310    803.749     -1.127      0.262   -2496.998     685.736\n",
       "en_109      -922.0902    812.957     -1.134      0.259   -2531.689     687.509\n",
       "en_110     -1462.5212    782.382     -1.869      0.064   -3011.583      86.541\n",
       "en_119     -1244.7059   1233.687     -1.009      0.315   -3687.319    1197.908\n",
       "en_120      -707.1840    756.195     -0.935      0.352   -2204.398     790.029\n",
       "en_121       615.1176   1007.331      0.611      0.543   -1379.327    2609.563\n",
       "en_122     -2155.4094    677.785     -3.180      0.002   -3497.377    -813.442\n",
       "en_130        59.6599    811.411      0.074      0.942   -1546.878    1666.198\n",
       "en_131        44.6522   1252.356      0.036      0.972   -2434.926    2524.231\n",
       "en_132     -2559.7873   1189.554     -2.152      0.033   -4915.021    -204.553\n",
       "en_134      1139.3780    911.501      1.250      0.214    -665.330    2944.086\n",
       "en_136      -195.2933    734.879     -0.266      0.791   -1650.303    1259.716\n",
       "en_140      -467.7835    939.374     -0.498      0.619   -2327.678    1392.111\n",
       "en_141        -3.2173    636.631     -0.005      0.996   -1263.702    1257.268\n",
       "en_145      2637.9784   1144.254      2.305      0.023     372.434    4903.522\n",
       "en_146     -2799.8701    687.510     -4.072      0.000   -4161.092   -1438.648\n",
       "en_151      1333.5700   1132.413      1.178      0.241    -908.528    3575.668\n",
       "en_152     -1039.9408    620.645     -1.676      0.096   -2268.774     188.893\n",
       "en_156     -3254.9478    622.672     -5.227      0.000   -4487.795   -2022.100\n",
       "en_161     -2656.3320   1117.564     -2.377      0.019   -4869.031    -443.633\n",
       "en_164      1085.8165    722.968      1.502      0.136    -345.611    2517.244\n",
       "en_171     -3131.3258    679.826     -4.606      0.000   -4477.333   -1785.318\n",
       "en_173        -3.9199   1079.664     -0.004      0.997   -2141.579    2133.739\n",
       "en_181     -3628.1229    532.457     -6.814      0.000   -4682.351   -2573.895\n",
       "en_183      3799.9722    792.011      4.798      0.000    2231.845    5368.099\n",
       "en_194      3944.7405    824.410      4.785      0.000    2312.466    5577.015\n",
       "en_203        52.1796   1397.873      0.037      0.970   -2715.511    2819.870\n",
       "en_209      4352.8322    629.465      6.915      0.000    3106.535    5599.129\n",
       "en_234      2604.2752    818.369      3.182      0.002     983.961    4224.589\n",
       "en_258       435.9171    889.201      0.490      0.625   -1324.639    2196.473\n",
       "en_304      3377.8385   1334.882      2.530      0.013     734.865    6020.812\n",
       "en_308       929.1305   1358.755      0.684      0.495   -1761.110    3619.370\n",
       "en_326     -4176.2941   1374.178     -3.039      0.003   -6897.071   -1455.518\n",
       "en_70       1924.2257   1216.574      1.582      0.116    -484.505    4332.957\n",
       "en_79      -1135.5130   1423.708     -0.798      0.427   -3954.355    1683.329\n",
       "en_80       2396.3729   1492.392      1.606      0.111    -558.458    5351.204\n",
       "en_90      -1210.8988    919.637     -1.317      0.190   -3031.716     609.918\n",
       "en_91      -1713.3727   1041.417     -1.645      0.103   -3775.305     348.560\n",
       "en_92      -1221.6963    896.235     -1.363      0.175   -2996.179     552.787\n",
       "en_97      -1086.4333    871.835     -1.246      0.215   -2812.607     639.740\n",
       "en_98      -1369.7009    841.719     -1.627      0.106   -3036.246     296.844\n",
       "en_108      -905.6310    803.749     -1.127      0.262   -2496.998     685.736\n",
       "en_109      -922.0902    812.957     -1.134      0.259   -2531.689     687.509\n",
       "en_110     -1462.5212    782.382     -1.869      0.064   -3011.583      86.541\n",
       "en_119     -1244.7059   1233.687     -1.009      0.315   -3687.319    1197.908\n",
       "en_120      -707.1840    756.195     -0.935      0.352   -2204.398     790.029\n",
       "en_121       615.1176   1007.331      0.611      0.543   -1379.327    2609.563\n",
       "en_122     -2155.4094    677.785     -3.180      0.002   -3497.377    -813.442\n",
       "en_130        59.6599    811.411      0.074      0.942   -1546.878    1666.198\n",
       "en_131        44.6522   1252.356      0.036      0.972   -2434.926    2524.231\n",
       "en_132     -2559.7873   1189.554     -2.152      0.033   -4915.021    -204.553\n",
       "en_134      1139.3780    911.501      1.250      0.214    -665.330    2944.086\n",
       "en_136      -195.2933    734.879     -0.266      0.791   -1650.303    1259.716\n",
       "en_140      -467.7835    939.374     -0.498      0.619   -2327.678    1392.111\n",
       "en_141        -3.2173    636.631     -0.005      0.996   -1263.702    1257.268\n",
       "en_145      2637.9784   1144.254      2.305      0.023     372.434    4903.522\n",
       "en_146     -2799.8701    687.510     -4.072      0.000   -4161.092   -1438.648\n",
       "en_151      1333.5700   1132.413      1.178      0.241    -908.528    3575.668\n",
       "en_152     -1039.9408    620.645     -1.676      0.096   -2268.774     188.893\n",
       "en_156     -3254.9478    622.672     -5.227      0.000   -4487.795   -2022.100\n",
       "en_161     -2656.3320   1117.564     -2.377      0.019   -4869.031    -443.633\n",
       "en_164      1085.8165    722.968      1.502      0.136    -345.611    2517.244\n",
       "en_171     -3131.3258    679.826     -4.606      0.000   -4477.333   -1785.318\n",
       "en_173        -3.9199   1079.664     -0.004      0.997   -2141.579    2133.739\n",
       "en_181     -3628.1229    532.457     -6.814      0.000   -4682.351   -2573.895\n",
       "en_183      3799.9722    792.011      4.798      0.000    2231.845    5368.099\n",
       "en_194      3944.7405    824.410      4.785      0.000    2312.466    5577.015\n",
       "en_203        52.1796   1397.873      0.037      0.970   -2715.511    2819.870\n",
       "en_209      4352.8322    629.465      6.915      0.000    3106.535    5599.129\n",
       "en_234      2604.2752    818.369      3.182      0.002     983.961    4224.589\n",
       "en_258       435.9171    889.201      0.490      0.625   -1324.639    2196.473\n",
       "en_304      3377.8385   1334.882      2.530      0.013     734.865    6020.812\n",
       "en_308       929.1305   1358.755      0.684      0.495   -1761.110    3619.370\n",
       "en_326     -4176.2941   1374.178     -3.039      0.003   -6897.071   -1455.518\n",
       "==============================================================================\n",
       "Omnibus:                       24.961   Durbin-Watson:                   2.149\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               42.345\n",
       "Skew:                           0.765   Prob(JB):                     6.38e-10\n",
       "Kurtosis:                       4.964   Cond. No.                     7.60e+19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.54e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y,sm.add_constant(x3))\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 98 164 110 141  90 234  70 122 258  92 108 120 136  97 173 130 181 134\n",
      " 146  91 156 151 140 121 203 131 209  79 109 119 152 183 171 161 194  61\n",
      " 326 308 145 304 132  80]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enginesize</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peakrpm</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>129.335366</td>\n",
       "      <td>106.743902</td>\n",
       "      <td>5127.743902</td>\n",
       "      <td>13742.491872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44.206192</td>\n",
       "      <td>40.903991</td>\n",
       "      <td>490.594139</td>\n",
       "      <td>8261.415500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>5118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>98.000000</td>\n",
       "      <td>71.500000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>7970.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>10921.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>146.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>16683.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>326.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>45400.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       enginesize  horsepower      peakrpm         price\n",
       "count  164.000000  164.000000   164.000000    164.000000\n",
       "mean   129.335366  106.743902  5127.743902  13742.491872\n",
       "std     44.206192   40.903991   490.594139   8261.415500\n",
       "min     61.000000   48.000000  4150.000000   5118.000000\n",
       "25%     98.000000   71.500000  4800.000000   7970.500000\n",
       "50%    120.000000   97.000000  5150.000000  10921.500000\n",
       "75%    146.000000  121.000000  5500.000000  16683.750000\n",
       "max    326.000000  288.000000  6600.000000  45400.000000"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train1.enginesize.unique())\n",
    "train1 = train1.assign(Class = train1[\"enginesize\"].apply(str))\n",
    "train1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dummies = pd.get_dummies(train1.Class, prefix = \"class\", drop_first = True)\n",
    "x5 = pd.concat([x4, class_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   53.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Nov 2021</td> <th>  Prob (F-statistic):</th> <td>9.62e-61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:26:38</td>     <th>  Log-Likelihood:    </th> <td> -1464.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   164</td>      <th>  AIC:               </th> <td>   3017.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   120</td>      <th>  BIC:               </th> <td>   3154.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    43</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>      <td>-3335.9583</td> <td> 2216.244</td> <td>   -1.505</td> <td> 0.135</td> <td>-7723.967</td> <td> 1052.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>enginesize</th> <td>  113.7530</td> <td>   10.529</td> <td>   10.804</td> <td> 0.000</td> <td>   92.907</td> <td>  134.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th> <td>   41.5343</td> <td>   16.382</td> <td>    2.535</td> <td> 0.013</td> <td>    9.100</td> <td>   73.969</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peakrpm</th>    <td>   -0.0944</td> <td>    0.642</td> <td>   -0.147</td> <td> 0.883</td> <td>   -1.365</td> <td>    1.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_70</th>      <td>  972.4126</td> <td>  395.972</td> <td>    2.456</td> <td> 0.015</td> <td>  188.416</td> <td> 1756.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_79</th>      <td> -556.1044</td> <td>  576.231</td> <td>   -0.965</td> <td> 0.336</td> <td>-1697.001</td> <td>  584.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_80</th>      <td> 1209.9888</td> <td>  580.290</td> <td>    2.085</td> <td> 0.039</td> <td>   61.056</td> <td> 2358.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_90</th>      <td> -592.1445</td> <td>  281.450</td> <td>   -2.104</td> <td> 0.037</td> <td>-1149.395</td> <td>  -34.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_91</th>      <td> -843.2311</td> <td>  343.285</td> <td>   -2.456</td> <td> 0.015</td> <td>-1522.911</td> <td> -163.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_92</th>      <td> -597.2427</td> <td>  262.677</td> <td>   -2.274</td> <td> 0.025</td> <td>-1117.325</td> <td>  -77.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_97</th>      <td> -528.8599</td> <td>  243.136</td> <td>   -2.175</td> <td> 0.032</td> <td>-1010.252</td> <td>  -47.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_98</th>      <td> -670.3434</td> <td>  223.909</td> <td>   -2.994</td> <td> 0.003</td> <td>-1113.668</td> <td> -227.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_108</th>     <td> -582.4078</td> <td>  299.800</td> <td>   -1.943</td> <td> 0.054</td> <td>-1175.992</td> <td>   11.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_109</th>     <td> -444.8853</td> <td>  262.326</td> <td>   -1.696</td> <td> 0.092</td> <td> -964.272</td> <td>   74.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_110</th>     <td> -714.9505</td> <td>  238.526</td> <td>   -2.997</td> <td> 0.003</td> <td>-1187.214</td> <td> -242.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_119</th>     <td> -604.6905</td> <td>  537.575</td> <td>   -1.125</td> <td> 0.263</td> <td>-1669.052</td> <td>  459.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_120</th>     <td> -335.7793</td> <td>  242.295</td> <td>   -1.386</td> <td> 0.168</td> <td> -815.507</td> <td>  143.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_121</th>     <td>  325.5218</td> <td>  393.685</td> <td>    0.827</td> <td> 0.410</td> <td> -453.948</td> <td> 1104.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_122</th>     <td>-1059.5915</td> <td>  175.350</td> <td>   -6.043</td> <td> 0.000</td> <td>-1406.771</td> <td> -712.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_130</th>     <td>   49.1453</td> <td>  284.052</td> <td>    0.173</td> <td> 0.863</td> <td> -513.258</td> <td>  611.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_131</th>     <td>   41.7917</td> <td>  552.956</td> <td>    0.076</td> <td> 0.940</td> <td>-1053.023</td> <td> 1136.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_132</th>     <td>-1260.2778</td> <td>  544.701</td> <td>   -2.314</td> <td> 0.022</td> <td>-2338.748</td> <td> -181.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_134</th>     <td>  589.6053</td> <td>  378.923</td> <td>    1.556</td> <td> 0.122</td> <td> -160.637</td> <td> 1339.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_136</th>     <td>  -77.4298</td> <td>  299.233</td> <td>   -0.259</td> <td> 0.796</td> <td> -669.890</td> <td>  515.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_140</th>     <td> -213.0739</td> <td>  390.699</td> <td>   -0.545</td> <td> 0.587</td> <td> -986.632</td> <td>  560.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_141</th>     <td>   19.3595</td> <td>  240.050</td> <td>    0.081</td> <td> 0.936</td> <td> -455.923</td> <td>  494.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_145</th>     <td> 1340.5584</td> <td>  530.733</td> <td>    2.526</td> <td> 0.013</td> <td>  289.744</td> <td> 2391.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_146</th>     <td>-1378.2156</td> <td>  270.472</td> <td>   -5.096</td> <td> 0.000</td> <td>-1913.731</td> <td> -842.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_151</th>     <td>  689.2557</td> <td>  533.515</td> <td>    1.292</td> <td> 0.199</td> <td> -367.067</td> <td> 1745.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_152</th>     <td> -497.3494</td> <td>  238.971</td> <td>   -2.081</td> <td> 0.040</td> <td> -970.496</td> <td>  -24.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_156</th>     <td>-1604.2518</td> <td>  249.928</td> <td>   -6.419</td> <td> 0.000</td> <td>-2099.091</td> <td>-1109.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_161</th>     <td>-1304.1926</td> <td>  532.328</td> <td>   -2.450</td> <td> 0.016</td> <td>-2358.164</td> <td> -250.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_164</th>     <td>  567.3324</td> <td>  324.124</td> <td>    1.750</td> <td> 0.083</td> <td>  -74.410</td> <td> 1209.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_171</th>     <td>-1540.1870</td> <td>  316.242</td> <td>   -4.870</td> <td> 0.000</td> <td>-2166.324</td> <td> -914.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_173</th>     <td>   23.8165</td> <td>  532.665</td> <td>    0.045</td> <td> 0.964</td> <td>-1030.824</td> <td> 1078.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_181</th>     <td>-1787.0829</td> <td>  252.820</td> <td>   -7.069</td> <td> 0.000</td> <td>-2287.649</td> <td>-1286.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_183</th>     <td> 1927.2651</td> <td>  390.434</td> <td>    4.936</td> <td> 0.000</td> <td> 1154.232</td> <td> 2700.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_194</th>     <td> 2001.3022</td> <td>  410.309</td> <td>    4.878</td> <td> 0.000</td> <td> 1188.918</td> <td> 2813.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_203</th>     <td>   56.3741</td> <td>  705.523</td> <td>    0.080</td> <td> 0.936</td> <td>-1340.513</td> <td> 1453.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_209</th>     <td> 2207.6019</td> <td>  314.389</td> <td>    7.022</td> <td> 0.000</td> <td> 1585.134</td> <td> 2830.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_234</th>     <td> 1337.0799</td> <td>  390.965</td> <td>    3.420</td> <td> 0.001</td> <td>  562.996</td> <td> 2111.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_258</th>     <td>  256.5070</td> <td>  395.688</td> <td>    0.648</td> <td> 0.518</td> <td> -526.928</td> <td> 1039.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_304</th>     <td> 1734.3797</td> <td>  541.372</td> <td>    3.204</td> <td> 0.002</td> <td>  662.500</td> <td> 2806.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_308</th>     <td>  510.6267</td> <td>  542.607</td> <td>    0.941</td> <td> 0.349</td> <td> -563.697</td> <td> 1584.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_326</th>     <td>-2039.3809</td> <td>  539.986</td> <td>   -3.777</td> <td> 0.000</td> <td>-3108.515</td> <td> -970.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_70</th>      <td>  972.4126</td> <td>  395.972</td> <td>    2.456</td> <td> 0.015</td> <td>  188.416</td> <td> 1756.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_79</th>      <td> -556.1044</td> <td>  576.231</td> <td>   -0.965</td> <td> 0.336</td> <td>-1697.001</td> <td>  584.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_80</th>      <td> 1209.9888</td> <td>  580.290</td> <td>    2.085</td> <td> 0.039</td> <td>   61.056</td> <td> 2358.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_90</th>      <td> -592.1445</td> <td>  281.450</td> <td>   -2.104</td> <td> 0.037</td> <td>-1149.395</td> <td>  -34.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_91</th>      <td> -843.2311</td> <td>  343.285</td> <td>   -2.456</td> <td> 0.015</td> <td>-1522.911</td> <td> -163.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_92</th>      <td> -597.2427</td> <td>  262.677</td> <td>   -2.274</td> <td> 0.025</td> <td>-1117.325</td> <td>  -77.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_97</th>      <td> -528.8599</td> <td>  243.136</td> <td>   -2.175</td> <td> 0.032</td> <td>-1010.252</td> <td>  -47.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_98</th>      <td> -670.3434</td> <td>  223.909</td> <td>   -2.994</td> <td> 0.003</td> <td>-1113.668</td> <td> -227.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_108</th>     <td> -582.4078</td> <td>  299.800</td> <td>   -1.943</td> <td> 0.054</td> <td>-1175.992</td> <td>   11.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_109</th>     <td> -444.8853</td> <td>  262.326</td> <td>   -1.696</td> <td> 0.092</td> <td> -964.272</td> <td>   74.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_110</th>     <td> -714.9505</td> <td>  238.526</td> <td>   -2.997</td> <td> 0.003</td> <td>-1187.214</td> <td> -242.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_119</th>     <td> -604.6905</td> <td>  537.575</td> <td>   -1.125</td> <td> 0.263</td> <td>-1669.052</td> <td>  459.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_120</th>     <td> -335.7793</td> <td>  242.295</td> <td>   -1.386</td> <td> 0.168</td> <td> -815.507</td> <td>  143.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_121</th>     <td>  325.5218</td> <td>  393.685</td> <td>    0.827</td> <td> 0.410</td> <td> -453.948</td> <td> 1104.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_122</th>     <td>-1059.5915</td> <td>  175.350</td> <td>   -6.043</td> <td> 0.000</td> <td>-1406.771</td> <td> -712.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_130</th>     <td>   49.1453</td> <td>  284.052</td> <td>    0.173</td> <td> 0.863</td> <td> -513.258</td> <td>  611.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_131</th>     <td>   41.7917</td> <td>  552.956</td> <td>    0.076</td> <td> 0.940</td> <td>-1053.023</td> <td> 1136.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_132</th>     <td>-1260.2778</td> <td>  544.701</td> <td>   -2.314</td> <td> 0.022</td> <td>-2338.748</td> <td> -181.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_134</th>     <td>  589.6053</td> <td>  378.923</td> <td>    1.556</td> <td> 0.122</td> <td> -160.637</td> <td> 1339.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_136</th>     <td>  -77.4298</td> <td>  299.233</td> <td>   -0.259</td> <td> 0.796</td> <td> -669.890</td> <td>  515.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_140</th>     <td> -213.0739</td> <td>  390.699</td> <td>   -0.545</td> <td> 0.587</td> <td> -986.632</td> <td>  560.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_141</th>     <td>   19.3595</td> <td>  240.050</td> <td>    0.081</td> <td> 0.936</td> <td> -455.923</td> <td>  494.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_145</th>     <td> 1340.5584</td> <td>  530.733</td> <td>    2.526</td> <td> 0.013</td> <td>  289.744</td> <td> 2391.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_146</th>     <td>-1378.2156</td> <td>  270.472</td> <td>   -5.096</td> <td> 0.000</td> <td>-1913.731</td> <td> -842.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_151</th>     <td>  689.2557</td> <td>  533.515</td> <td>    1.292</td> <td> 0.199</td> <td> -367.067</td> <td> 1745.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_152</th>     <td> -497.3494</td> <td>  238.971</td> <td>   -2.081</td> <td> 0.040</td> <td> -970.496</td> <td>  -24.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_156</th>     <td>-1604.2518</td> <td>  249.928</td> <td>   -6.419</td> <td> 0.000</td> <td>-2099.091</td> <td>-1109.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_161</th>     <td>-1304.1926</td> <td>  532.328</td> <td>   -2.450</td> <td> 0.016</td> <td>-2358.164</td> <td> -250.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_164</th>     <td>  567.3324</td> <td>  324.124</td> <td>    1.750</td> <td> 0.083</td> <td>  -74.410</td> <td> 1209.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_171</th>     <td>-1540.1870</td> <td>  316.242</td> <td>   -4.870</td> <td> 0.000</td> <td>-2166.324</td> <td> -914.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_173</th>     <td>   23.8165</td> <td>  532.665</td> <td>    0.045</td> <td> 0.964</td> <td>-1030.824</td> <td> 1078.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_181</th>     <td>-1787.0829</td> <td>  252.820</td> <td>   -7.069</td> <td> 0.000</td> <td>-2287.649</td> <td>-1286.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_183</th>     <td> 1927.2651</td> <td>  390.434</td> <td>    4.936</td> <td> 0.000</td> <td> 1154.232</td> <td> 2700.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_194</th>     <td> 2001.3022</td> <td>  410.309</td> <td>    4.878</td> <td> 0.000</td> <td> 1188.918</td> <td> 2813.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_203</th>     <td>   56.3741</td> <td>  705.523</td> <td>    0.080</td> <td> 0.936</td> <td>-1340.513</td> <td> 1453.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_209</th>     <td> 2207.6019</td> <td>  314.389</td> <td>    7.022</td> <td> 0.000</td> <td> 1585.134</td> <td> 2830.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_234</th>     <td> 1337.0799</td> <td>  390.965</td> <td>    3.420</td> <td> 0.001</td> <td>  562.996</td> <td> 2111.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_258</th>     <td>  256.5070</td> <td>  395.688</td> <td>    0.648</td> <td> 0.518</td> <td> -526.928</td> <td> 1039.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_304</th>     <td> 1734.3797</td> <td>  541.372</td> <td>    3.204</td> <td> 0.002</td> <td>  662.500</td> <td> 2806.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_308</th>     <td>  510.6267</td> <td>  542.607</td> <td>    0.941</td> <td> 0.349</td> <td> -563.697</td> <td> 1584.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_326</th>     <td>-2039.3809</td> <td>  539.986</td> <td>   -3.777</td> <td> 0.000</td> <td>-3108.515</td> <td> -970.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_70</th>      <td>  972.4126</td> <td>  395.972</td> <td>    2.456</td> <td> 0.015</td> <td>  188.416</td> <td> 1756.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_79</th>      <td> -556.1044</td> <td>  576.231</td> <td>   -0.965</td> <td> 0.336</td> <td>-1697.001</td> <td>  584.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_80</th>      <td> 1209.9888</td> <td>  580.290</td> <td>    2.085</td> <td> 0.039</td> <td>   61.056</td> <td> 2358.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_90</th>      <td> -592.1445</td> <td>  281.450</td> <td>   -2.104</td> <td> 0.037</td> <td>-1149.395</td> <td>  -34.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_91</th>      <td> -843.2311</td> <td>  343.285</td> <td>   -2.456</td> <td> 0.015</td> <td>-1522.911</td> <td> -163.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_92</th>      <td> -597.2427</td> <td>  262.677</td> <td>   -2.274</td> <td> 0.025</td> <td>-1117.325</td> <td>  -77.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_97</th>      <td> -528.8599</td> <td>  243.136</td> <td>   -2.175</td> <td> 0.032</td> <td>-1010.252</td> <td>  -47.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_98</th>      <td> -670.3434</td> <td>  223.909</td> <td>   -2.994</td> <td> 0.003</td> <td>-1113.668</td> <td> -227.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_108</th>     <td> -582.4078</td> <td>  299.800</td> <td>   -1.943</td> <td> 0.054</td> <td>-1175.992</td> <td>   11.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_109</th>     <td> -444.8853</td> <td>  262.326</td> <td>   -1.696</td> <td> 0.092</td> <td> -964.272</td> <td>   74.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_110</th>     <td> -714.9505</td> <td>  238.526</td> <td>   -2.997</td> <td> 0.003</td> <td>-1187.214</td> <td> -242.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_119</th>     <td> -604.6905</td> <td>  537.575</td> <td>   -1.125</td> <td> 0.263</td> <td>-1669.052</td> <td>  459.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_120</th>     <td> -335.7793</td> <td>  242.295</td> <td>   -1.386</td> <td> 0.168</td> <td> -815.507</td> <td>  143.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_121</th>     <td>  325.5218</td> <td>  393.685</td> <td>    0.827</td> <td> 0.410</td> <td> -453.948</td> <td> 1104.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_122</th>     <td>-1059.5915</td> <td>  175.350</td> <td>   -6.043</td> <td> 0.000</td> <td>-1406.771</td> <td> -712.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_130</th>     <td>   49.1453</td> <td>  284.052</td> <td>    0.173</td> <td> 0.863</td> <td> -513.258</td> <td>  611.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_131</th>     <td>   41.7917</td> <td>  552.956</td> <td>    0.076</td> <td> 0.940</td> <td>-1053.023</td> <td> 1136.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_132</th>     <td>-1260.2778</td> <td>  544.701</td> <td>   -2.314</td> <td> 0.022</td> <td>-2338.748</td> <td> -181.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_134</th>     <td>  589.6053</td> <td>  378.923</td> <td>    1.556</td> <td> 0.122</td> <td> -160.637</td> <td> 1339.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_136</th>     <td>  -77.4298</td> <td>  299.233</td> <td>   -0.259</td> <td> 0.796</td> <td> -669.890</td> <td>  515.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_140</th>     <td> -213.0739</td> <td>  390.699</td> <td>   -0.545</td> <td> 0.587</td> <td> -986.632</td> <td>  560.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_141</th>     <td>   19.3595</td> <td>  240.050</td> <td>    0.081</td> <td> 0.936</td> <td> -455.923</td> <td>  494.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_145</th>     <td> 1340.5584</td> <td>  530.733</td> <td>    2.526</td> <td> 0.013</td> <td>  289.744</td> <td> 2391.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_146</th>     <td>-1378.2156</td> <td>  270.472</td> <td>   -5.096</td> <td> 0.000</td> <td>-1913.731</td> <td> -842.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_151</th>     <td>  689.2557</td> <td>  533.515</td> <td>    1.292</td> <td> 0.199</td> <td> -367.067</td> <td> 1745.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_152</th>     <td> -497.3494</td> <td>  238.971</td> <td>   -2.081</td> <td> 0.040</td> <td> -970.496</td> <td>  -24.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_156</th>     <td>-1604.2518</td> <td>  249.928</td> <td>   -6.419</td> <td> 0.000</td> <td>-2099.091</td> <td>-1109.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_161</th>     <td>-1304.1926</td> <td>  532.328</td> <td>   -2.450</td> <td> 0.016</td> <td>-2358.164</td> <td> -250.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_164</th>     <td>  567.3324</td> <td>  324.124</td> <td>    1.750</td> <td> 0.083</td> <td>  -74.410</td> <td> 1209.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_171</th>     <td>-1540.1870</td> <td>  316.242</td> <td>   -4.870</td> <td> 0.000</td> <td>-2166.324</td> <td> -914.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_173</th>     <td>   23.8165</td> <td>  532.665</td> <td>    0.045</td> <td> 0.964</td> <td>-1030.824</td> <td> 1078.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_181</th>     <td>-1787.0829</td> <td>  252.820</td> <td>   -7.069</td> <td> 0.000</td> <td>-2287.649</td> <td>-1286.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_183</th>     <td> 1927.2651</td> <td>  390.434</td> <td>    4.936</td> <td> 0.000</td> <td> 1154.232</td> <td> 2700.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_194</th>     <td> 2001.3022</td> <td>  410.309</td> <td>    4.878</td> <td> 0.000</td> <td> 1188.918</td> <td> 2813.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_203</th>     <td>   56.3741</td> <td>  705.523</td> <td>    0.080</td> <td> 0.936</td> <td>-1340.513</td> <td> 1453.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_209</th>     <td> 2207.6019</td> <td>  314.389</td> <td>    7.022</td> <td> 0.000</td> <td> 1585.134</td> <td> 2830.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_234</th>     <td> 1337.0799</td> <td>  390.965</td> <td>    3.420</td> <td> 0.001</td> <td>  562.996</td> <td> 2111.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_258</th>     <td>  256.5070</td> <td>  395.688</td> <td>    0.648</td> <td> 0.518</td> <td> -526.928</td> <td> 1039.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_304</th>     <td> 1734.3797</td> <td>  541.372</td> <td>    3.204</td> <td> 0.002</td> <td>  662.500</td> <td> 2806.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_308</th>     <td>  510.6267</td> <td>  542.607</td> <td>    0.941</td> <td> 0.349</td> <td> -563.697</td> <td> 1584.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>en_326</th>     <td>-2039.3809</td> <td>  539.986</td> <td>   -3.777</td> <td> 0.000</td> <td>-3108.515</td> <td> -970.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_109</th>  <td> -444.8853</td> <td>  262.326</td> <td>   -1.696</td> <td> 0.092</td> <td> -964.272</td> <td>   74.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_110</th>  <td> -714.9505</td> <td>  238.526</td> <td>   -2.997</td> <td> 0.003</td> <td>-1187.214</td> <td> -242.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_119</th>  <td> -604.6905</td> <td>  537.575</td> <td>   -1.125</td> <td> 0.263</td> <td>-1669.052</td> <td>  459.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_120</th>  <td> -335.7793</td> <td>  242.295</td> <td>   -1.386</td> <td> 0.168</td> <td> -815.507</td> <td>  143.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_121</th>  <td>  325.5218</td> <td>  393.685</td> <td>    0.827</td> <td> 0.410</td> <td> -453.948</td> <td> 1104.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_122</th>  <td>-1059.5915</td> <td>  175.350</td> <td>   -6.043</td> <td> 0.000</td> <td>-1406.771</td> <td> -712.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_130</th>  <td>   49.1453</td> <td>  284.052</td> <td>    0.173</td> <td> 0.863</td> <td> -513.258</td> <td>  611.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_131</th>  <td>   41.7917</td> <td>  552.956</td> <td>    0.076</td> <td> 0.940</td> <td>-1053.023</td> <td> 1136.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_132</th>  <td>-1260.2778</td> <td>  544.701</td> <td>   -2.314</td> <td> 0.022</td> <td>-2338.748</td> <td> -181.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_134</th>  <td>  589.6053</td> <td>  378.923</td> <td>    1.556</td> <td> 0.122</td> <td> -160.637</td> <td> 1339.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_136</th>  <td>  -77.4298</td> <td>  299.233</td> <td>   -0.259</td> <td> 0.796</td> <td> -669.890</td> <td>  515.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_140</th>  <td> -213.0739</td> <td>  390.699</td> <td>   -0.545</td> <td> 0.587</td> <td> -986.632</td> <td>  560.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_141</th>  <td>   19.3595</td> <td>  240.050</td> <td>    0.081</td> <td> 0.936</td> <td> -455.923</td> <td>  494.642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_145</th>  <td> 1340.5584</td> <td>  530.733</td> <td>    2.526</td> <td> 0.013</td> <td>  289.744</td> <td> 2391.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_146</th>  <td>-1378.2156</td> <td>  270.472</td> <td>   -5.096</td> <td> 0.000</td> <td>-1913.731</td> <td> -842.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_151</th>  <td>  689.2557</td> <td>  533.515</td> <td>    1.292</td> <td> 0.199</td> <td> -367.067</td> <td> 1745.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_152</th>  <td> -497.3494</td> <td>  238.971</td> <td>   -2.081</td> <td> 0.040</td> <td> -970.496</td> <td>  -24.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_156</th>  <td>-1604.2518</td> <td>  249.928</td> <td>   -6.419</td> <td> 0.000</td> <td>-2099.091</td> <td>-1109.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_161</th>  <td>-1304.1926</td> <td>  532.328</td> <td>   -2.450</td> <td> 0.016</td> <td>-2358.164</td> <td> -250.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_164</th>  <td>  567.3324</td> <td>  324.124</td> <td>    1.750</td> <td> 0.083</td> <td>  -74.410</td> <td> 1209.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_171</th>  <td>-1540.1870</td> <td>  316.242</td> <td>   -4.870</td> <td> 0.000</td> <td>-2166.324</td> <td> -914.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_173</th>  <td>   23.8165</td> <td>  532.665</td> <td>    0.045</td> <td> 0.964</td> <td>-1030.824</td> <td> 1078.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_181</th>  <td>-1787.0829</td> <td>  252.820</td> <td>   -7.069</td> <td> 0.000</td> <td>-2287.649</td> <td>-1286.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_183</th>  <td> 1927.2651</td> <td>  390.434</td> <td>    4.936</td> <td> 0.000</td> <td> 1154.232</td> <td> 2700.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_194</th>  <td> 2001.3022</td> <td>  410.309</td> <td>    4.878</td> <td> 0.000</td> <td> 1188.918</td> <td> 2813.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_203</th>  <td>   56.3741</td> <td>  705.523</td> <td>    0.080</td> <td> 0.936</td> <td>-1340.513</td> <td> 1453.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_209</th>  <td> 2207.6019</td> <td>  314.389</td> <td>    7.022</td> <td> 0.000</td> <td> 1585.134</td> <td> 2830.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_234</th>  <td> 1337.0799</td> <td>  390.965</td> <td>    3.420</td> <td> 0.001</td> <td>  562.996</td> <td> 2111.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_258</th>  <td>  256.5070</td> <td>  395.688</td> <td>    0.648</td> <td> 0.518</td> <td> -526.928</td> <td> 1039.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_304</th>  <td> 1734.3797</td> <td>  541.372</td> <td>    3.204</td> <td> 0.002</td> <td>  662.500</td> <td> 2806.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_308</th>  <td>  510.6267</td> <td>  542.607</td> <td>    0.941</td> <td> 0.349</td> <td> -563.697</td> <td> 1584.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_326</th>  <td>-2039.3809</td> <td>  539.986</td> <td>   -3.777</td> <td> 0.000</td> <td>-3108.515</td> <td> -970.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_61</th>   <td>   35.7896</td> <td> 1971.794</td> <td>    0.018</td> <td> 0.986</td> <td>-3868.225</td> <td> 3939.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_70</th>   <td>  972.4126</td> <td>  395.972</td> <td>    2.456</td> <td> 0.015</td> <td>  188.416</td> <td> 1756.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_79</th>   <td> -556.1044</td> <td>  576.231</td> <td>   -0.965</td> <td> 0.336</td> <td>-1697.001</td> <td>  584.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_80</th>   <td> 1209.9888</td> <td>  580.290</td> <td>    2.085</td> <td> 0.039</td> <td>   61.056</td> <td> 2358.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_90</th>   <td> -592.1445</td> <td>  281.450</td> <td>   -2.104</td> <td> 0.037</td> <td>-1149.395</td> <td>  -34.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_91</th>   <td> -843.2311</td> <td>  343.285</td> <td>   -2.456</td> <td> 0.015</td> <td>-1522.911</td> <td> -163.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_92</th>   <td> -597.2427</td> <td>  262.677</td> <td>   -2.274</td> <td> 0.025</td> <td>-1117.325</td> <td>  -77.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_97</th>   <td> -528.8599</td> <td>  243.136</td> <td>   -2.175</td> <td> 0.032</td> <td>-1010.252</td> <td>  -47.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>class_98</th>   <td> -670.3434</td> <td>  223.909</td> <td>   -2.994</td> <td> 0.003</td> <td>-1113.668</td> <td> -227.019</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.961</td> <th>  Durbin-Watson:     </th> <td>   2.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  42.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.765</td> <th>  Prob(JB):          </th> <td>6.38e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.964</td> <th>  Cond. No.          </th> <td>6.01e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The input rank is higher than the number of observations.<br/>[3] The smallest eigenvalue is 1.2e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.951\n",
       "Model:                            OLS   Adj. R-squared:                  0.933\n",
       "Method:                 Least Squares   F-statistic:                     53.79\n",
       "Date:                Fri, 12 Nov 2021   Prob (F-statistic):           9.62e-61\n",
       "Time:                        20:26:38   Log-Likelihood:                -1464.6\n",
       "No. Observations:                 164   AIC:                             3017.\n",
       "Df Residuals:                     120   BIC:                             3154.\n",
       "Df Model:                          43                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -3335.9583   2216.244     -1.505      0.135   -7723.967    1052.051\n",
       "enginesize   113.7530     10.529     10.804      0.000      92.907     134.599\n",
       "horsepower    41.5343     16.382      2.535      0.013       9.100      73.969\n",
       "peakrpm       -0.0944      0.642     -0.147      0.883      -1.365       1.176\n",
       "en_70        972.4126    395.972      2.456      0.015     188.416    1756.409\n",
       "en_79       -556.1044    576.231     -0.965      0.336   -1697.001     584.793\n",
       "en_80       1209.9888    580.290      2.085      0.039      61.056    2358.922\n",
       "en_90       -592.1445    281.450     -2.104      0.037   -1149.395     -34.893\n",
       "en_91       -843.2311    343.285     -2.456      0.015   -1522.911    -163.552\n",
       "en_92       -597.2427    262.677     -2.274      0.025   -1117.325     -77.160\n",
       "en_97       -528.8599    243.136     -2.175      0.032   -1010.252     -47.468\n",
       "en_98       -670.3434    223.909     -2.994      0.003   -1113.668    -227.019\n",
       "en_108      -582.4078    299.800     -1.943      0.054   -1175.992      11.176\n",
       "en_109      -444.8853    262.326     -1.696      0.092    -964.272      74.502\n",
       "en_110      -714.9505    238.526     -2.997      0.003   -1187.214    -242.687\n",
       "en_119      -604.6905    537.575     -1.125      0.263   -1669.052     459.671\n",
       "en_120      -335.7793    242.295     -1.386      0.168    -815.507     143.948\n",
       "en_121       325.5218    393.685      0.827      0.410    -453.948    1104.992\n",
       "en_122     -1059.5915    175.350     -6.043      0.000   -1406.771    -712.412\n",
       "en_130        49.1453    284.052      0.173      0.863    -513.258     611.548\n",
       "en_131        41.7917    552.956      0.076      0.940   -1053.023    1136.606\n",
       "en_132     -1260.2778    544.701     -2.314      0.022   -2338.748    -181.808\n",
       "en_134       589.6053    378.923      1.556      0.122    -160.637    1339.847\n",
       "en_136       -77.4298    299.233     -0.259      0.796    -669.890     515.030\n",
       "en_140      -213.0739    390.699     -0.545      0.587    -986.632     560.484\n",
       "en_141        19.3595    240.050      0.081      0.936    -455.923     494.642\n",
       "en_145      1340.5584    530.733      2.526      0.013     289.744    2391.373\n",
       "en_146     -1378.2156    270.472     -5.096      0.000   -1913.731    -842.700\n",
       "en_151       689.2557    533.515      1.292      0.199    -367.067    1745.578\n",
       "en_152      -497.3494    238.971     -2.081      0.040    -970.496     -24.203\n",
       "en_156     -1604.2518    249.928     -6.419      0.000   -2099.091   -1109.413\n",
       "en_161     -1304.1926    532.328     -2.450      0.016   -2358.164    -250.221\n",
       "en_164       567.3324    324.124      1.750      0.083     -74.410    1209.075\n",
       "en_171     -1540.1870    316.242     -4.870      0.000   -2166.324    -914.050\n",
       "en_173        23.8165    532.665      0.045      0.964   -1030.824    1078.457\n",
       "en_181     -1787.0829    252.820     -7.069      0.000   -2287.649   -1286.517\n",
       "en_183      1927.2651    390.434      4.936      0.000    1154.232    2700.298\n",
       "en_194      2001.3022    410.309      4.878      0.000    1188.918    2813.686\n",
       "en_203        56.3741    705.523      0.080      0.936   -1340.513    1453.261\n",
       "en_209      2207.6019    314.389      7.022      0.000    1585.134    2830.070\n",
       "en_234      1337.0799    390.965      3.420      0.001     562.996    2111.164\n",
       "en_258       256.5070    395.688      0.648      0.518    -526.928    1039.942\n",
       "en_304      1734.3797    541.372      3.204      0.002     662.500    2806.259\n",
       "en_308       510.6267    542.607      0.941      0.349    -563.697    1584.950\n",
       "en_326     -2039.3809    539.986     -3.777      0.000   -3108.515    -970.247\n",
       "en_70        972.4126    395.972      2.456      0.015     188.416    1756.409\n",
       "en_79       -556.1044    576.231     -0.965      0.336   -1697.001     584.793\n",
       "en_80       1209.9888    580.290      2.085      0.039      61.056    2358.922\n",
       "en_90       -592.1445    281.450     -2.104      0.037   -1149.395     -34.893\n",
       "en_91       -843.2311    343.285     -2.456      0.015   -1522.911    -163.552\n",
       "en_92       -597.2427    262.677     -2.274      0.025   -1117.325     -77.160\n",
       "en_97       -528.8599    243.136     -2.175      0.032   -1010.252     -47.468\n",
       "en_98       -670.3434    223.909     -2.994      0.003   -1113.668    -227.019\n",
       "en_108      -582.4078    299.800     -1.943      0.054   -1175.992      11.176\n",
       "en_109      -444.8853    262.326     -1.696      0.092    -964.272      74.502\n",
       "en_110      -714.9505    238.526     -2.997      0.003   -1187.214    -242.687\n",
       "en_119      -604.6905    537.575     -1.125      0.263   -1669.052     459.671\n",
       "en_120      -335.7793    242.295     -1.386      0.168    -815.507     143.948\n",
       "en_121       325.5218    393.685      0.827      0.410    -453.948    1104.992\n",
       "en_122     -1059.5915    175.350     -6.043      0.000   -1406.771    -712.412\n",
       "en_130        49.1453    284.052      0.173      0.863    -513.258     611.548\n",
       "en_131        41.7917    552.956      0.076      0.940   -1053.023    1136.606\n",
       "en_132     -1260.2778    544.701     -2.314      0.022   -2338.748    -181.808\n",
       "en_134       589.6053    378.923      1.556      0.122    -160.637    1339.847\n",
       "en_136       -77.4298    299.233     -0.259      0.796    -669.890     515.030\n",
       "en_140      -213.0739    390.699     -0.545      0.587    -986.632     560.484\n",
       "en_141        19.3595    240.050      0.081      0.936    -455.923     494.642\n",
       "en_145      1340.5584    530.733      2.526      0.013     289.744    2391.373\n",
       "en_146     -1378.2156    270.472     -5.096      0.000   -1913.731    -842.700\n",
       "en_151       689.2557    533.515      1.292      0.199    -367.067    1745.578\n",
       "en_152      -497.3494    238.971     -2.081      0.040    -970.496     -24.203\n",
       "en_156     -1604.2518    249.928     -6.419      0.000   -2099.091   -1109.413\n",
       "en_161     -1304.1926    532.328     -2.450      0.016   -2358.164    -250.221\n",
       "en_164       567.3324    324.124      1.750      0.083     -74.410    1209.075\n",
       "en_171     -1540.1870    316.242     -4.870      0.000   -2166.324    -914.050\n",
       "en_173        23.8165    532.665      0.045      0.964   -1030.824    1078.457\n",
       "en_181     -1787.0829    252.820     -7.069      0.000   -2287.649   -1286.517\n",
       "en_183      1927.2651    390.434      4.936      0.000    1154.232    2700.298\n",
       "en_194      2001.3022    410.309      4.878      0.000    1188.918    2813.686\n",
       "en_203        56.3741    705.523      0.080      0.936   -1340.513    1453.261\n",
       "en_209      2207.6019    314.389      7.022      0.000    1585.134    2830.070\n",
       "en_234      1337.0799    390.965      3.420      0.001     562.996    2111.164\n",
       "en_258       256.5070    395.688      0.648      0.518    -526.928    1039.942\n",
       "en_304      1734.3797    541.372      3.204      0.002     662.500    2806.259\n",
       "en_308       510.6267    542.607      0.941      0.349    -563.697    1584.950\n",
       "en_326     -2039.3809    539.986     -3.777      0.000   -3108.515    -970.247\n",
       "en_70        972.4126    395.972      2.456      0.015     188.416    1756.409\n",
       "en_79       -556.1044    576.231     -0.965      0.336   -1697.001     584.793\n",
       "en_80       1209.9888    580.290      2.085      0.039      61.056    2358.922\n",
       "en_90       -592.1445    281.450     -2.104      0.037   -1149.395     -34.893\n",
       "en_91       -843.2311    343.285     -2.456      0.015   -1522.911    -163.552\n",
       "en_92       -597.2427    262.677     -2.274      0.025   -1117.325     -77.160\n",
       "en_97       -528.8599    243.136     -2.175      0.032   -1010.252     -47.468\n",
       "en_98       -670.3434    223.909     -2.994      0.003   -1113.668    -227.019\n",
       "en_108      -582.4078    299.800     -1.943      0.054   -1175.992      11.176\n",
       "en_109      -444.8853    262.326     -1.696      0.092    -964.272      74.502\n",
       "en_110      -714.9505    238.526     -2.997      0.003   -1187.214    -242.687\n",
       "en_119      -604.6905    537.575     -1.125      0.263   -1669.052     459.671\n",
       "en_120      -335.7793    242.295     -1.386      0.168    -815.507     143.948\n",
       "en_121       325.5218    393.685      0.827      0.410    -453.948    1104.992\n",
       "en_122     -1059.5915    175.350     -6.043      0.000   -1406.771    -712.412\n",
       "en_130        49.1453    284.052      0.173      0.863    -513.258     611.548\n",
       "en_131        41.7917    552.956      0.076      0.940   -1053.023    1136.606\n",
       "en_132     -1260.2778    544.701     -2.314      0.022   -2338.748    -181.808\n",
       "en_134       589.6053    378.923      1.556      0.122    -160.637    1339.847\n",
       "en_136       -77.4298    299.233     -0.259      0.796    -669.890     515.030\n",
       "en_140      -213.0739    390.699     -0.545      0.587    -986.632     560.484\n",
       "en_141        19.3595    240.050      0.081      0.936    -455.923     494.642\n",
       "en_145      1340.5584    530.733      2.526      0.013     289.744    2391.373\n",
       "en_146     -1378.2156    270.472     -5.096      0.000   -1913.731    -842.700\n",
       "en_151       689.2557    533.515      1.292      0.199    -367.067    1745.578\n",
       "en_152      -497.3494    238.971     -2.081      0.040    -970.496     -24.203\n",
       "en_156     -1604.2518    249.928     -6.419      0.000   -2099.091   -1109.413\n",
       "en_161     -1304.1926    532.328     -2.450      0.016   -2358.164    -250.221\n",
       "en_164       567.3324    324.124      1.750      0.083     -74.410    1209.075\n",
       "en_171     -1540.1870    316.242     -4.870      0.000   -2166.324    -914.050\n",
       "en_173        23.8165    532.665      0.045      0.964   -1030.824    1078.457\n",
       "en_181     -1787.0829    252.820     -7.069      0.000   -2287.649   -1286.517\n",
       "en_183      1927.2651    390.434      4.936      0.000    1154.232    2700.298\n",
       "en_194      2001.3022    410.309      4.878      0.000    1188.918    2813.686\n",
       "en_203        56.3741    705.523      0.080      0.936   -1340.513    1453.261\n",
       "en_209      2207.6019    314.389      7.022      0.000    1585.134    2830.070\n",
       "en_234      1337.0799    390.965      3.420      0.001     562.996    2111.164\n",
       "en_258       256.5070    395.688      0.648      0.518    -526.928    1039.942\n",
       "en_304      1734.3797    541.372      3.204      0.002     662.500    2806.259\n",
       "en_308       510.6267    542.607      0.941      0.349    -563.697    1584.950\n",
       "en_326     -2039.3809    539.986     -3.777      0.000   -3108.515    -970.247\n",
       "class_109   -444.8853    262.326     -1.696      0.092    -964.272      74.502\n",
       "class_110   -714.9505    238.526     -2.997      0.003   -1187.214    -242.687\n",
       "class_119   -604.6905    537.575     -1.125      0.263   -1669.052     459.671\n",
       "class_120   -335.7793    242.295     -1.386      0.168    -815.507     143.948\n",
       "class_121    325.5218    393.685      0.827      0.410    -453.948    1104.992\n",
       "class_122  -1059.5915    175.350     -6.043      0.000   -1406.771    -712.412\n",
       "class_130     49.1453    284.052      0.173      0.863    -513.258     611.548\n",
       "class_131     41.7917    552.956      0.076      0.940   -1053.023    1136.606\n",
       "class_132  -1260.2778    544.701     -2.314      0.022   -2338.748    -181.808\n",
       "class_134    589.6053    378.923      1.556      0.122    -160.637    1339.847\n",
       "class_136    -77.4298    299.233     -0.259      0.796    -669.890     515.030\n",
       "class_140   -213.0739    390.699     -0.545      0.587    -986.632     560.484\n",
       "class_141     19.3595    240.050      0.081      0.936    -455.923     494.642\n",
       "class_145   1340.5584    530.733      2.526      0.013     289.744    2391.373\n",
       "class_146  -1378.2156    270.472     -5.096      0.000   -1913.731    -842.700\n",
       "class_151    689.2557    533.515      1.292      0.199    -367.067    1745.578\n",
       "class_152   -497.3494    238.971     -2.081      0.040    -970.496     -24.203\n",
       "class_156  -1604.2518    249.928     -6.419      0.000   -2099.091   -1109.413\n",
       "class_161  -1304.1926    532.328     -2.450      0.016   -2358.164    -250.221\n",
       "class_164    567.3324    324.124      1.750      0.083     -74.410    1209.075\n",
       "class_171  -1540.1870    316.242     -4.870      0.000   -2166.324    -914.050\n",
       "class_173     23.8165    532.665      0.045      0.964   -1030.824    1078.457\n",
       "class_181  -1787.0829    252.820     -7.069      0.000   -2287.649   -1286.517\n",
       "class_183   1927.2651    390.434      4.936      0.000    1154.232    2700.298\n",
       "class_194   2001.3022    410.309      4.878      0.000    1188.918    2813.686\n",
       "class_203     56.3741    705.523      0.080      0.936   -1340.513    1453.261\n",
       "class_209   2207.6019    314.389      7.022      0.000    1585.134    2830.070\n",
       "class_234   1337.0799    390.965      3.420      0.001     562.996    2111.164\n",
       "class_258    256.5070    395.688      0.648      0.518    -526.928    1039.942\n",
       "class_304   1734.3797    541.372      3.204      0.002     662.500    2806.259\n",
       "class_308    510.6267    542.607      0.941      0.349    -563.697    1584.950\n",
       "class_326  -2039.3809    539.986     -3.777      0.000   -3108.515    -970.247\n",
       "class_61      35.7896   1971.794      0.018      0.986   -3868.225    3939.804\n",
       "class_70     972.4126    395.972      2.456      0.015     188.416    1756.409\n",
       "class_79    -556.1044    576.231     -0.965      0.336   -1697.001     584.793\n",
       "class_80    1209.9888    580.290      2.085      0.039      61.056    2358.922\n",
       "class_90    -592.1445    281.450     -2.104      0.037   -1149.395     -34.893\n",
       "class_91    -843.2311    343.285     -2.456      0.015   -1522.911    -163.552\n",
       "class_92    -597.2427    262.677     -2.274      0.025   -1117.325     -77.160\n",
       "class_97    -528.8599    243.136     -2.175      0.032   -1010.252     -47.468\n",
       "class_98    -670.3434    223.909     -2.994      0.003   -1113.668    -227.019\n",
       "==============================================================================\n",
       "Omnibus:                       24.961   Durbin-Watson:                   2.149\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               42.345\n",
       "Skew:                           0.765   Prob(JB):                     6.38e-10\n",
       "Kurtosis:                       4.964   Cond. No.                     6.01e+18\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The input rank is higher than the number of observations.\n",
       "[3] The smallest eigenvalue is 1.2e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols3 = sm.OLS(y,sm.add_constant(x5))\n",
    "fit3 = ols3.fit()\n",
    "fit3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829.1309458819412"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = fit3.predict(sm.add_constant(x5))\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y, yhat))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 (20 pts)\n",
    "Make a tree based regression model for the car price using whatever variables you think are appropriate from the data in train.csv.  This may be a single regression tree or a decision forest.  Variable selection, dummy coding should be parts of your code and the model. Compute the RMSE of your final model when predicting on all of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF1 = RandomForestRegressor(n_estimators = 100, min_samples_split = 10, max_features = 7, random_state = 7)\n",
    "RF1fit = RF1.fit(x5, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2129.0544651208256"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = RF1fit.predict(x5)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y, yhat))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF2 = RandomForestRegressor(n_estimators = 150, min_samples_split = 2, max_features = 10, random_state = 7)\n",
    "RF2fit = RF1.fit(x5, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2129.0544651208256"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = RF2fit.predict(x5)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y, yhat))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (10 pts)\n",
    "Perform an 80-20 train-test split on the training data.  Call the training data from this split train0 and the test data from this split test0.  Retrain both of your final models from problems 1 and 2 using the data in train0 and use these newly trained models to predict the price for the data in test0.  Report the RMSE for each model and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x5, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2791.483210320262"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols = sm.OLS(ytrain,sm.add_constant(xtrain))\n",
    "fit_ols = ols.fit()\n",
    "yhat_ols = fit_ols.predict(sm.add_constant(xtest))\n",
    "RMSE_ols = np.sqrt(metrics.mean_squared_error(ytest, yhat_ols))\n",
    "RMSE_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2670.7460099040313"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestRegressor(n_estimators = 150, min_samples_split = 2, max_features = 10, random_state = 17)\n",
    "fit_RF = RF.fit(xtrain,ytrain) \n",
    "yhat_RF = fit_RF.predict(xtest)\n",
    "RMSE_RF = np.sqrt(metrics.mean_squared_error(ytest, yhat_RF))\n",
    "RMSE_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "Use your final model from either problem 1 or problem 2 to make predictions on the test data.  Save your predictions as a csv with a single column called \"yhat\".  To have your predictions considered for the contest, you must name your csv \"lastname_firstname_predictions.csv\".  We have included some code below to help you read in the test data and save your csv file.  You must upload your csv file to canvas with your html and ipynb files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test-3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['108', '109', '110', '119', '120', '121', '122', '130', '131',\n",
       "       '132', '134', '136', '140', '141', '145', '146', '151', '152',\n",
       "       '156', '161', '164', '171', '173', '181', '183', '194', '203',\n",
       "       '209', '234', '258', '304', '308', '326', '61', '70', '79', '80',\n",
       "       '90', '91', '92', '97', '98'], dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(train1[\"Class\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['103', '108', '109', '110', '111', '120', '121', '122', '131',\n",
       "       '132', '136', '141', '146', '181', '183', '194', '90', '91', '92',\n",
       "       '97', '98'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(test1[\"Class\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test1.assign(Class = test1[\"enginesize\"].apply(str))\n",
    "numcols = [\"enginesize\", \"horsepower\", \"peakrpm\"]\n",
    "x1test = test1[numcols]\n",
    "en_test_dummies = pd.get_dummies(test1.enginesize, prefix = \"en\", drop_first = True)\n",
    "hp_test_dummies = pd.get_dummies(test1.horsepower, prefix = \"hp\", drop_first = True)\n",
    "pr_test_dummies = pd.get_dummies(test1.peakrpm, prefix = \"pr\", drop_first = True)\n",
    "x2test = pd.concat([x1test, en_test_dummies], axis = 1)\n",
    "x3test = pd.concat([x2test, hp_test_dummies], axis = 1)\n",
    "x4test = pd.concat([x3test, pr_test_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_test_dummies = pd.get_dummies(test1.Class, prefix = \"class\", drop_first = True)\n",
    "x5test = pd.concat([x2test, class_test_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming your predictions are a 1-d numpy array named yhat, this cell will write them to a csv\n",
    "predictions =pd.DataFrame(yhat, columns = [\"yhat\"])\n",
    "\n",
    "#Edit this string so that your last name and first name are included in the file name.\n",
    "file = \"lastname_firstname_predictions.csv\"\n",
    "predictions.to_csv(file, header = True, index = False, sep = \",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
